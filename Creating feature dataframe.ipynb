{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c5db5c",
   "metadata": {},
   "source": [
    "# Creating feature dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96066d",
   "metadata": {},
   "source": [
    "## Loading libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime #used for date and time calculations\n",
    "pd.options.mode.chained_assignment = None  # remove an annoying warning\n",
    "\n",
    "# loading the dataset\n",
    "data = pyreadr.read_r('/path/to/file.rds')\n",
    "df=data[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a841c11",
   "metadata": {},
   "source": [
    "## Add columns IS_PEAKTIME and IS_WEEKDAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with weekday (0 = monday, 1 = tuesday, ...)\n",
    "df['WEEKDAY'] = df['TIME_REAL'].dt.dayofweek\n",
    "\n",
    "# adding column with boolean is_weekday (True = weekday, False = weekend)\n",
    "df[\"IS_WEEKDAY_BOOL\"] = df[\"WEEKDAY\"] <= 4\n",
    "\n",
    "# convert boolean to an int\n",
    "df[\"IS_WEEKDAY\"] = df[\"IS_WEEKDAY_BOOL\"].astype(int)\n",
    "\n",
    "# variables that decide peaktimes\n",
    "peak_m_s = datetime.datetime(1999, 11, 13, 6)\n",
    "peak_m_e = datetime.datetime(1999, 11, 13, 9)\n",
    "peak_e_s = datetime.datetime(1999, 11, 13, 16)\n",
    "peak_e_e = datetime.datetime(1999, 11, 13, 19)\n",
    "\n",
    "# add column with a boolean for peaktime\n",
    "df['IS_PEAKTIME_BOOL'] = (((df['TIME_REAL'].dt.time < peak_m_e.time()) & (df['TIME_REAL'].dt.time >= peak_m_s.time())) | ((df['TIME_REAL'].dt.time < peak_e_e.time()) & (df['TIME_REAL'].dt.time >= peak_e_s.time())))\n",
    "\n",
    "#convert the boolean to an integer\n",
    "df['IS_PEAKTIME'] = df['IS_PEAKTIME_BOOL'].astype(int)\n",
    "\n",
    "# remove columns\n",
    "df = df.drop([\"IS_PEAKTIME_BOOL\"], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488ced9",
   "metadata": {},
   "source": [
    "## Add columns PRECEDING_STATION and PRECEDING_DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e070ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True) #reset index to access rows in loops\n",
    "\n",
    "preceding_station = [df.loc[0, 'STATION']]\n",
    "preceding_delay = [df.loc[0, 'DELAY']]\n",
    "\n",
    "for i in range (1, len(df)):\n",
    "    preceding_station.append(df.loc[i-1, 'STATION'])\n",
    "    preceding_delay.append(df.loc[i-1, 'DELAY'])\n",
    "    \n",
    "df['PRECEDING_STATION'] = preceding_station\n",
    "df['PRECEDING_DELAY'] = preceding_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfa20d",
   "metadata": {},
   "source": [
    "## Add column TRAVEL_TIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e265961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with the travel times from preceding to actual station\n",
    "time = [df.loc[0, 'TIME_PLANNED']]\n",
    "\n",
    "for i in range(1,len(df)):\n",
    "    time.append(df.loc[i-1, 'TIME_PLANNED'])\n",
    "    \n",
    "df['PRECEDING_TIME'] = time\n",
    "\n",
    "df['TRAVEL_TIME_TIMEDELTA'] = df['TIME_PLANNED'] - df['PRECEDING_TIME']\n",
    "df['TRAVEL_TIME'] = df['TRAVEL_TIME_TIMEDELTA'].dt.total_seconds() / 60\n",
    "\n",
    "# remove columns\n",
    "df = df.drop([\"PRECEDING_TIME\", \"TRAVEL_TIME_TIMEDELTA\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e7693",
   "metadata": {},
   "source": [
    "## Reduce dataframe to trains in the corridor Chur - Zurich HB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing all stations in the corridor:\n",
    "stations = ['ZÃ¼rich HB', 'ZÃ¼rich Wiedikon', 'ZÃ¼rich Enge', 'ZÃ¼rich Wollishofen', 'Kilchberg', 'RÃ¼schlikon', 'Thalwil', 'Oberrieden', 'Horgen', 'Au ZH', 'WÃ¤denswil', 'Richterswil', 'BÃ¤ch', 'Freienbach SBB', 'PfÃ¤ffikon SZ', 'Altendorf', 'Lachen', 'Siebnen-Wangen', 'SchÃ¼belbach-Buttikon', 'Reichenburg', 'Bilten', 'ZiegelbrÃ¼cke', 'MÃ¼hlehorn', 'Murg', 'Unterterzen', 'Mols', 'Walenstadt', 'Flums', 'Mels', 'Sargans', 'Bad Ragaz', 'Maienfeld', 'Landquart', 'Chur']\n",
    "\n",
    "stations_df = pd.DataFrame(stations, columns = ['stations'])\n",
    "\n",
    "#create a list of booleans whether the station is in the corridor or not\n",
    "check_station = []\n",
    "check_previous_station = []\n",
    "\n",
    "for i in range (len(df)):\n",
    "    check_station.append(df.loc[i, 'STATION'] in stations)\n",
    "    check_previous_station.append(df.loc[i, 'PRECEDING_STATION'] in stations)\n",
    "    \n",
    "#append the list to the last column of the dataframe \n",
    "df['CHECK_STATION'] = check_station\n",
    "df['CHECK_PRECEDING_STATION'] = check_previous_station\n",
    "\n",
    "# create a dataframe just with trains in the corridor Chur - Zürich HB\n",
    "df = df.loc[(df['CHECK_STATION'] == True) & (df['CHECK_PRECEDING_STATION'] == True)]\n",
    "\n",
    "# remove columns\n",
    "df = df.drop([\"CHECK_STATION\"], axis=1)\n",
    "df = df.drop([\"CHECK_PRECEDING_STATION\"], axis=1)\n",
    "\n",
    "# resetting the indexes to acces rows in the loop\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272bd13",
   "metadata": {},
   "source": [
    "## Add column PRECEDING_DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import distance matrix\n",
    "dima = pd.read_csv('/path/to/file.csv', sep=',')\n",
    "\n",
    "# convert dataframe to numpy array\n",
    "dima = np.array(dima)\n",
    "\n",
    "# name columns and rows\n",
    "distance_matrix = pd.DataFrame(dima, columns = ['ZÃ¼rich HB', 'ZÃ¼rich Wiedikon', 'ZÃ¼rich Enge', 'ZÃ¼rich Wollishofen', 'Kilchberg', 'RÃ¼schlikon', 'Thalwil', 'Oberrieden', 'Horgen', 'Au ZH', 'WÃ¤denswil', 'Richterswil', 'BÃ¤ch', 'Freienbach SBB', 'PfÃ¤ffikon SZ', 'Altendorf', 'Lachen', 'Siebnen-Wangen', 'SchÃ¼belbach-Buttikon', 'Reichenburg', 'Bilten', 'ZiegelbrÃ¼cke', 'MÃ¼hlehorn', 'Murg', 'Unterterzen', 'Mols', 'Walenstadt', 'Flums', 'Mels', 'Sargans', 'Bad Ragaz', 'Maienfeld', 'Landquart', 'Chur'], \n",
    "                  index=['ZÃ¼rich HB', 'ZÃ¼rich Wiedikon', 'ZÃ¼rich Enge', 'ZÃ¼rich Wollishofen', 'Kilchberg', 'RÃ¼schlikon', 'Thalwil', 'Oberrieden', 'Horgen', 'Au ZH', 'WÃ¤denswil', 'Richterswil', 'BÃ¤ch', 'Freienbach SBB', 'PfÃ¤ffikon SZ', 'Altendorf', 'Lachen', 'Siebnen-Wangen', 'SchÃ¼belbach-Buttikon', 'Reichenburg', 'Bilten', 'ZiegelbrÃ¼cke', 'MÃ¼hlehorn', 'Murg', 'Unterterzen', 'Mols', 'Walenstadt', 'Flums', 'Mels', 'Sargans', 'Bad Ragaz', 'Maienfeld', 'Landquart', 'Chur']) \n",
    "\n",
    "# creating a list with all the distances between preceding and actual station\n",
    "distance = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    distance.append(distance_matrix.loc[(df.loc[i,'STATION']), (df.loc[i, 'PRECEDING_STATION'])])\n",
    "\n",
    "# add list with distances as new column in df\n",
    "df['PRECEDING_DISTANCE'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bffc6",
   "metadata": {},
   "source": [
    "## Export dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dad175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe to containing only arrival events\n",
    "df = df.loc[df['EVENT_TYPE'] == 'ARRIVAL'] \n",
    "\n",
    "# export as csv file for faster imports in other code files\n",
    "df.to_csv (r'/path/to/file.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
